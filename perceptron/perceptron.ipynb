{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Author: fzy\n",
    "@Date: 2019-05-23 14:53:54\n",
    "@LastEditors: Zhenying\n",
    "@LastEditTime: 2019-05-23 15:02:31\n",
    "@Description: \n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.log函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(algorithm_name):\n",
    "    LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    DATE_FORMAT = \"%Y-%m-%d %H:%M:%S %p\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(LOG_FORMAT, DATE_FORMAT)\n",
    "    chlr = logging.StreamHandler()\n",
    "    chlr.setFormatter(formatter)\n",
    "    chlr.setLevel('INFO')\n",
    "    fhlr = logging.FileHandler(algorithm_name + '.log')\n",
    "    fhlr.setFormatter(formatter)\n",
    "    logger.addHandler(chlr)\n",
    "    logger.addHandler(fhlr)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(\"perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, logg):\n",
    "    logg.info(\"===== Loading Data =====\")\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    # 获得类别标签\n",
    "    labels = df.iloc[:, 0].values\n",
    "    # 获得数据\n",
    "    datas = df.iloc[:, 1:].values\n",
    "    # 转换成二分类，分0类和非0类，将原始类别为0的标记为1，原始类别非0的标记为-1\n",
    "    labels = np.where(labels > 0, 1, -1)\n",
    "    # 将数据除255\n",
    "    datas = datas / 255.\n",
    "    logg.info(\"===== Loaded Data  =====\")\n",
    "    return datas, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, labels = load_data(\"../data/mnist_train.csv\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.感知机训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(datas, labels, logg, iters=100):\n",
    "    logg.info(\"===== start train =====\")\n",
    "    # 得到训练数据的数量和维度\n",
    "    m, n = datas.shape\n",
    "    # 初始化权重和偏置\n",
    "    w = np.zeros((1, n))\n",
    "    b = 0\n",
    "    # 初始化学习率\n",
    "    eta = 0.0001\n",
    "    # 进行iter次迭代计算\n",
    "    for now_iter in range(iters):\n",
    "        for i in range(m):\n",
    "            xi = datas[i]\n",
    "            yi = labels[i]\n",
    "            xi = np.mat(xi)\n",
    "            yi = np.mat(yi)\n",
    "            # 判断是否是误分类样本\n",
    "            if (-1 * yi * (w * xi.T + b)) >= 0:\n",
    "                # 对于误分类样本，进行梯度下降，更新w和b\n",
    "                w = w + eta *  yi * xi\n",
    "                b = b + eta * yi\n",
    "        logg.info('Iter [%d]:[%d]' % (now_iter, iters))\n",
    "    logg.info(\"===== trained =====\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w, b = perceptron(datas, labels, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(datas, labels, w, b, logg):\n",
    "    logg.info(\"===== start testing =====\")\n",
    "    m, n = datas.shape\n",
    "    # 用来统计预测错误的个数\n",
    "    errorCnt = 0\n",
    "    # 对所有样本进行预测\n",
    "    for i in range(m):\n",
    "        xi = datas[i]\n",
    "        yi = labels[i]\n",
    "        xi = np.mat(xi)\n",
    "        yi = np.mat(yi)\n",
    "        res = -1 * yi * (w * xi.T + b)\n",
    "        if res >= 0: errorCnt += 1\n",
    "    accruRate = 1 - (errorCnt / m)\n",
    "    logg.info(\"===== tested =====\")\n",
    "    logg.info(\"accRate: {0}\".format(accruRate))\n",
    "    return accruRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, labels = load_data(\"../data/mnist_test.csv\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accRate = test(datas, labels, w, b, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
